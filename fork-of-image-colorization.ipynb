{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eefef23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:05.218074Z",
     "iopub.status.busy": "2024-12-11T17:35:05.217795Z",
     "iopub.status.idle": "2024-12-11T17:35:10.982053Z",
     "shell.execute_reply": "2024-12-11T17:35:10.981143Z"
    },
    "papermill": {
     "duration": 5.770838,
     "end_time": "2024-12-11T17:35:10.984140",
     "exception": false,
     "start_time": "2024-12-11T17:35:05.213302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25d423d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:10.992364Z",
     "iopub.status.busy": "2024-12-11T17:35:10.992013Z",
     "iopub.status.idle": "2024-12-11T17:35:11.089705Z",
     "shell.execute_reply": "2024-12-11T17:35:11.088887Z"
    },
    "papermill": {
     "duration": 0.103396,
     "end_time": "2024-12-11T17:35:11.091272",
     "exception": false,
     "start_time": "2024-12-11T17:35:10.987876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a9314ea2430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurations\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "np.random.seed(25)\n",
    "torch.manual_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7084d699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:11.098875Z",
     "iopub.status.busy": "2024-12-11T17:35:11.098576Z",
     "iopub.status.idle": "2024-12-11T17:35:11.102511Z",
     "shell.execute_reply": "2024-12-11T17:35:11.101883Z"
    },
    "papermill": {
     "duration": 0.009251,
     "end_time": "2024-12-11T17:35:11.103925",
     "exception": false,
     "start_time": "2024-12-11T17:35:11.094674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = \"/kaggle/input/coco25k/images\"\n",
    "working_dir = \"/kaggle/working/\"\n",
    "IMG_DIM = 256\n",
    "batch_size = 32 #adjust to 16 if required\n",
    "learning_rate = 2e-4 #optimal rate for training GANs\n",
    "NUM_EPOCHS = 20\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "lambda_L1 = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6920edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:11.111035Z",
     "iopub.status.busy": "2024-12-11T17:35:11.110775Z",
     "iopub.status.idle": "2024-12-11T17:35:11.117040Z",
     "shell.execute_reply": "2024-12-11T17:35:11.116361Z"
    },
    "papermill": {
     "duration": 0.011592,
     "end_time": "2024-12-11T17:35:11.118639",
     "exception": false,
     "start_time": "2024-12-11T17:35:11.107047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class COCODataset(Dataset):\n",
    "    def __init__(self, img_dir, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_paths = []\n",
    "        all_images = [os.path.join(img_dir, file) for file in os.listdir(img_dir) \n",
    "                      if file.endswith('.jpg')]\n",
    "        self.image_paths = random.sample(all_images, min(len(all_images), 10000))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype('float32')  #change to float16 for faster training\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = img_lab[[0], ...]/ 50.0 - 1.0\n",
    "        ab = img_lab[[1, 2], ...]/ 128.0 \n",
    "        return {'L': L, 'ab': ab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10874b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:11.126702Z",
     "iopub.status.busy": "2024-12-11T17:35:11.126477Z",
     "iopub.status.idle": "2024-12-11T17:35:11.130274Z",
     "shell.execute_reply": "2024-12-11T17:35:11.129498Z"
    },
    "papermill": {
     "duration": 0.008902,
     "end_time": "2024-12-11T17:35:11.131754",
     "exception": false,
     "start_time": "2024-12-11T17:35:11.122852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure to not add jitter/ noise as it affects the image colors\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_DIM, IMG_DIM), Image.BICUBIC),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e9cc6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:11.138805Z",
     "iopub.status.busy": "2024-12-11T17:35:11.138560Z",
     "iopub.status.idle": "2024-12-11T17:35:12.175741Z",
     "shell.execute_reply": "2024-12-11T17:35:12.175115Z"
    },
    "papermill": {
     "duration": 1.042612,
     "end_time": "2024-12-11T17:35:12.177369",
     "exception": false,
     "start_time": "2024-12-11T17:35:11.134757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = COCODataset(img_dir, train_transforms)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f0db53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:12.184699Z",
     "iopub.status.busy": "2024-12-11T17:35:12.184454Z",
     "iopub.status.idle": "2024-12-11T17:35:14.819202Z",
     "shell.execute_reply": "2024-12-11T17:35:14.817742Z"
    },
    "papermill": {
     "duration": 2.640411,
     "end_time": "2024-12-11T17:35:14.821041",
     "exception": false,
     "start_time": "2024-12-11T17:35:12.180630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256]) torch.Size([32, 2, 256, 256])\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "data = next(iter(train_dl))\n",
    "Ls, abs_ = data['L'], data['ab']\n",
    "print(Ls.shape, abs_.shape)\n",
    "print(len(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c80567",
   "metadata": {
    "papermill": {
     "duration": 0.00307,
     "end_time": "2024-12-11T17:35:14.827580",
     "exception": false,
     "start_time": "2024-12-11T17:35:14.824510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introducing ResNet backed UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a5cc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:14.835291Z",
     "iopub.status.busy": "2024-12-11T17:35:14.834999Z",
     "iopub.status.idle": "2024-12-11T17:35:20.076730Z",
     "shell.execute_reply": "2024-12-11T17:35:20.075815Z"
    },
    "papermill": {
     "duration": 5.248044,
     "end_time": "2024-12-11T17:35:20.078810",
     "exception": false,
     "start_time": "2024-12-11T17:35:14.830766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 200MB/s]\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.learner import create_body\n",
    "# from torchvision.models.resnet import resnet34\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "\n",
    "resnet34 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76900f5a",
   "metadata": {
    "papermill": {
     "duration": 0.004979,
     "end_time": "2024-12-11T17:35:20.089342",
     "exception": false,
     "start_time": "2024-12-11T17:35:20.084363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Building Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc654e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:20.098606Z",
     "iopub.status.busy": "2024-12-11T17:35:20.098277Z",
     "iopub.status.idle": "2024-12-11T17:35:20.103142Z",
     "shell.execute_reply": "2024-12-11T17:35:20.102304Z"
    },
    "papermill": {
     "duration": 0.011148,
     "end_time": "2024-12-11T17:35:20.104901",
     "exception": false,
     "start_time": "2024-12-11T17:35:20.093753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_res_unet(n_input=1, n_output=2, size=IMG_DIM):\n",
    "    body = create_body(resnet34, pretrained=True, n_in=n_input, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size))\n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d89437",
   "metadata": {
    "papermill": {
     "duration": 0.004905,
     "end_time": "2024-12-11T17:35:20.114852",
     "exception": false,
     "start_time": "2024-12-11T17:35:20.109947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Building Patch Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5952e2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:20.124448Z",
     "iopub.status.busy": "2024-12-11T17:35:20.124167Z",
     "iopub.status.idle": "2024-12-11T17:35:20.132115Z",
     "shell.execute_reply": "2024-12-11T17:35:20.131376Z"
    },
    "papermill": {
     "duration": 0.013982,
     "end_time": "2024-12-11T17:35:20.133690",
     "exception": false,
     "start_time": "2024-12-11T17:35:20.119708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchDisc(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        # We define the first and last layers outside the loop since they are required to not have activation \n",
    "        # and normalization according to the paper\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
    "                          for i in range(n_down)] \n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n",
    "        self.model = nn.Sequential(*model)                                                   \n",
    "        \n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]         \n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db8dc52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:20.142215Z",
     "iopub.status.busy": "2024-12-11T17:35:20.141944Z",
     "iopub.status.idle": "2024-12-11T17:35:20.146296Z",
     "shell.execute_reply": "2024-12-11T17:35:20.145607Z"
    },
    "papermill": {
     "duration": 0.010353,
     "end_time": "2024-12-11T17:35:20.147781",
     "exception": false,
     "start_time": "2024-12-11T17:35:20.137428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining loss functions\n",
    "'''PatchGAN uses a combination of adversarial and L1 loss.'''\n",
    "\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()  \n",
    "l1_loss = nn.L1Loss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10553703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:20.156482Z",
     "iopub.status.busy": "2024-12-11T17:35:20.155816Z",
     "iopub.status.idle": "2024-12-11T17:35:21.297761Z",
     "shell.execute_reply": "2024-12-11T17:35:21.297049Z"
    },
    "papermill": {
     "duration": 1.148235,
     "end_time": "2024-12-11T17:35:21.299687",
     "exception": false,
     "start_time": "2024-12-11T17:35:20.151452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "net_G = build_res_unet(n_input=1, n_output=2, size=IMG_DIM).to(device)\n",
    "net_D = PatchDisc(input_c=3).to(device)\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_G = optim.Adam(net_G.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(net_D.parameters(), lr=learning_rate, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5391098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:21.308685Z",
     "iopub.status.busy": "2024-12-11T17:35:21.308418Z",
     "iopub.status.idle": "2024-12-11T17:35:21.316023Z",
     "shell.execute_reply": "2024-12-11T17:35:21.315254Z"
    },
    "papermill": {
     "duration": 0.013732,
     "end_time": "2024-12-11T17:35:21.317613",
     "exception": false,
     "start_time": "2024-12-11T17:35:21.303881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=15, gamma=0.5)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=15, gamma=0.5)\n",
    "\n",
    "def pretrain_G(net_G, train_dl, opt, criterion, epochs=20):\n",
    "    net_G.train()  # Set generator to training mode\n",
    "    for e in range(epochs):\n",
    "        total_loss = 0.0  # Accumulate loss for each epoch\n",
    "        for data in tqdm(train_dl, desc=f\"Pretraining Epoch {e + 1}/{epochs}\"):\n",
    "            L, ab = data['L'].to(device), data['ab'].to(device)\n",
    "            preds = net_G(L)  # Predicted color channels\n",
    "            loss = criterion(preds, ab)  # L1 loss between predicted and ground truth\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dl)\n",
    "        print(f\"Pretraining Epoch {e + 1}/{epochs}, Average L1 Loss: {avg_loss:.5f}\")\n",
    "        if (e + 1) % 5 == 0:  # Save every 5 epochs\n",
    "            torch.save(net_G.state_dict(), f\"generator_pretrain_epoch_{e+1}.pth\")\n",
    "        \n",
    "        # Step scheduler\n",
    "        scheduler_G.step()\n",
    "\n",
    "        \n",
    "\n",
    "pretrain_epochs = 20\n",
    "pretrain_criterion = nn.L1Loss()\n",
    "pretrain_optimizer = optim.Adam(net_G.parameters(), lr=learning_rate, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4178952d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T17:35:21.326187Z",
     "iopub.status.busy": "2024-12-11T17:35:21.325939Z",
     "iopub.status.idle": "2024-12-11T23:42:20.182884Z",
     "shell.execute_reply": "2024-12-11T23:42:20.181749Z"
    },
    "papermill": {
     "duration": 22018.863291,
     "end_time": "2024-12-11T23:42:20.184541",
     "exception": false,
     "start_time": "2024-12-11T17:35:21.321250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 1/20: 100%|██████████| 313/313 [07:00<00:00,  1.34s/it]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 1/20, Average L1 Loss: 0.08041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 2/20: 100%|██████████| 313/313 [07:12<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 2/20, Average L1 Loss: 0.06756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 3/20: 100%|██████████| 313/313 [07:10<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 3/20, Average L1 Loss: 0.06629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 4/20: 100%|██████████| 313/313 [07:10<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 4/20, Average L1 Loss: 0.06520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 5/20: 100%|██████████| 313/313 [07:09<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 5/20, Average L1 Loss: 0.06436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 6/20: 100%|██████████| 313/313 [07:09<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 6/20, Average L1 Loss: 0.06339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 7/20: 100%|██████████| 313/313 [07:08<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 7/20, Average L1 Loss: 0.06252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 8/20: 100%|██████████| 313/313 [07:07<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 8/20, Average L1 Loss: 0.06156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 9/20: 100%|██████████| 313/313 [07:08<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 9/20, Average L1 Loss: 0.06051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 10/20: 100%|██████████| 313/313 [07:08<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 10/20, Average L1 Loss: 0.05967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 11/20: 100%|██████████| 313/313 [07:08<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 11/20, Average L1 Loss: 0.05855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 12/20: 100%|██████████| 313/313 [07:07<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 12/20, Average L1 Loss: 0.05773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 13/20: 100%|██████████| 313/313 [07:06<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 13/20, Average L1 Loss: 0.05676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 14/20: 100%|██████████| 313/313 [07:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 14/20, Average L1 Loss: 0.05602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 15/20: 100%|██████████| 313/313 [07:04<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 15/20, Average L1 Loss: 0.05534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 16/20: 100%|██████████| 313/313 [07:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 16/20, Average L1 Loss: 0.05446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 17/20: 100%|██████████| 313/313 [07:04<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 17/20, Average L1 Loss: 0.05341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 18/20: 100%|██████████| 313/313 [07:03<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 18/20, Average L1 Loss: 0.05264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 19/20: 100%|██████████| 313/313 [07:02<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 19/20, Average L1 Loss: 0.05169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 20/20: 100%|██████████| 313/313 [07:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 20/20, Average L1 Loss: 0.05112\n",
      "Epoch [0/20], Step [0/313], D Loss: 0.7157, G Loss: 6.3963\n",
      "Epoch [0/20], Step [100/313], D Loss: 0.6496, G Loss: 5.7424\n",
      "Epoch [0/20], Step [200/313], D Loss: 0.5984, G Loss: 5.6708\n",
      "Epoch [0/20], Step [300/313], D Loss: 0.6543, G Loss: 5.6039\n",
      "Epoch [1/20], Step [0/313], D Loss: 0.6748, G Loss: 3.5439\n",
      "Epoch [1/20], Step [100/313], D Loss: 0.6992, G Loss: 3.3087\n",
      "Epoch [1/20], Step [200/313], D Loss: 0.7048, G Loss: 3.4984\n",
      "Epoch [1/20], Step [300/313], D Loss: 0.6198, G Loss: 3.6826\n",
      "Epoch [2/20], Step [0/313], D Loss: 0.5790, G Loss: 2.3902\n",
      "Epoch [2/20], Step [100/313], D Loss: 0.7070, G Loss: 2.5440\n",
      "Epoch [2/20], Step [200/313], D Loss: 0.6166, G Loss: 2.5743\n",
      "Epoch [2/20], Step [300/313], D Loss: 0.6643, G Loss: 2.7944\n",
      "Epoch [3/20], Step [0/313], D Loss: 0.7362, G Loss: 1.9359\n",
      "Epoch [3/20], Step [100/313], D Loss: 0.6846, G Loss: 1.9452\n",
      "Epoch [3/20], Step [200/313], D Loss: 0.7040, G Loss: 2.1007\n",
      "Epoch [3/20], Step [300/313], D Loss: 0.6467, G Loss: 2.3702\n",
      "Epoch [4/20], Step [0/313], D Loss: 0.6543, G Loss: 1.7829\n",
      "Epoch [4/20], Step [100/313], D Loss: 0.6885, G Loss: 1.8210\n",
      "Epoch [4/20], Step [200/313], D Loss: 0.7027, G Loss: 1.8746\n",
      "Epoch [4/20], Step [300/313], D Loss: 0.6953, G Loss: 1.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2597784347.py:83: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 14 negative Z values that have been clipped to zero\n",
      "  rgb_image = lab2rgb(lab_image)  # Convert LAB to RGB\n",
      "/tmp/ipykernel_23/2597784347.py:83: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 4 negative Z values that have been clipped to zero\n",
      "  rgb_image = lab2rgb(lab_image)  # Convert LAB to RGB\n",
      "/tmp/ipykernel_23/2597784347.py:83: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 7 negative Z values that have been clipped to zero\n",
      "  rgb_image = lab2rgb(lab_image)  # Convert LAB to RGB\n",
      "/tmp/ipykernel_23/2597784347.py:83: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 1 negative Z values that have been clipped to zero\n",
      "  rgb_image = lab2rgb(lab_image)  # Convert LAB to RGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample outputs for epoch 5\n",
      "Saved model weights for epoch 5\n",
      "Epoch [5/20], Step [0/313], D Loss: 0.7298, G Loss: 1.5612\n",
      "Epoch [5/20], Step [100/313], D Loss: 0.6795, G Loss: 1.5933\n",
      "Epoch [5/20], Step [200/313], D Loss: 0.7094, G Loss: 1.6117\n",
      "Epoch [5/20], Step [300/313], D Loss: 0.7245, G Loss: 1.6176\n",
      "Epoch [6/20], Step [0/313], D Loss: 0.7222, G Loss: 1.4334\n",
      "Epoch [6/20], Step [100/313], D Loss: 0.7176, G Loss: 1.3290\n",
      "Epoch [6/20], Step [200/313], D Loss: 0.7080, G Loss: 1.4440\n",
      "Epoch [6/20], Step [300/313], D Loss: 0.7188, G Loss: 1.5024\n",
      "Epoch [7/20], Step [0/313], D Loss: 0.6844, G Loss: 1.3412\n",
      "Epoch [7/20], Step [100/313], D Loss: 0.7155, G Loss: 1.4053\n",
      "Epoch [7/20], Step [200/313], D Loss: 0.7044, G Loss: 1.3899\n",
      "Epoch [7/20], Step [300/313], D Loss: 0.6697, G Loss: 1.4601\n",
      "Epoch [8/20], Step [0/313], D Loss: 0.6855, G Loss: 1.2846\n",
      "Epoch [8/20], Step [100/313], D Loss: 0.6939, G Loss: 1.2085\n",
      "Epoch [8/20], Step [200/313], D Loss: 0.6804, G Loss: 1.2903\n",
      "Epoch [8/20], Step [300/313], D Loss: 0.6993, G Loss: 1.3162\n",
      "Epoch [9/20], Step [0/313], D Loss: 0.6929, G Loss: 1.3185\n",
      "Epoch [9/20], Step [100/313], D Loss: 0.6882, G Loss: 1.2252\n",
      "Epoch [9/20], Step [200/313], D Loss: 0.6894, G Loss: 1.1811\n",
      "Epoch [9/20], Step [300/313], D Loss: 0.6992, G Loss: 1.1519\n",
      "Saved sample outputs for epoch 10\n",
      "Saved model weights for epoch 10\n",
      "Epoch [10/20], Step [0/313], D Loss: 0.6878, G Loss: 1.1681\n",
      "Epoch [10/20], Step [100/313], D Loss: 0.6916, G Loss: 1.1365\n",
      "Epoch [10/20], Step [200/313], D Loss: 0.7003, G Loss: 1.1487\n",
      "Epoch [10/20], Step [300/313], D Loss: 0.6821, G Loss: 1.1768\n",
      "Epoch [11/20], Step [0/313], D Loss: 0.6764, G Loss: 1.1816\n",
      "Epoch [11/20], Step [100/313], D Loss: 0.6890, G Loss: 1.1357\n",
      "Epoch [11/20], Step [200/313], D Loss: 0.6616, G Loss: 1.1504\n",
      "Epoch [11/20], Step [300/313], D Loss: 0.6728, G Loss: 1.1549\n",
      "Epoch [12/20], Step [0/313], D Loss: 0.6929, G Loss: 1.1428\n",
      "Epoch [12/20], Step [100/313], D Loss: 0.6741, G Loss: 1.1139\n",
      "Epoch [12/20], Step [200/313], D Loss: 0.6932, G Loss: 1.0415\n",
      "Epoch [12/20], Step [300/313], D Loss: 0.6924, G Loss: 1.0439\n",
      "Epoch [13/20], Step [0/313], D Loss: 0.6754, G Loss: 1.0672\n",
      "Epoch [13/20], Step [100/313], D Loss: 0.6787, G Loss: 0.9761\n",
      "Epoch [13/20], Step [200/313], D Loss: 0.6838, G Loss: 1.0553\n",
      "Epoch [13/20], Step [300/313], D Loss: 0.6795, G Loss: 1.0491\n",
      "Epoch [14/20], Step [0/313], D Loss: 0.6877, G Loss: 1.0415\n",
      "Epoch [14/20], Step [100/313], D Loss: 0.6885, G Loss: 1.0096\n",
      "Epoch [14/20], Step [200/313], D Loss: 0.6964, G Loss: 1.0171\n",
      "Epoch [14/20], Step [300/313], D Loss: 0.6794, G Loss: 0.9811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2597784347.py:83: UserWarning: Conversion from CIE-LAB, via XYZ to sRGB color space resulted in 6 negative Z values that have been clipped to zero\n",
      "  rgb_image = lab2rgb(lab_image)  # Convert LAB to RGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample outputs for epoch 15\n",
      "Saved model weights for epoch 15\n",
      "Epoch [15/20], Step [0/313], D Loss: 0.6778, G Loss: 1.0594\n",
      "Epoch [15/20], Step [100/313], D Loss: 0.6861, G Loss: 1.0063\n",
      "Epoch [15/20], Step [200/313], D Loss: 0.6868, G Loss: 1.0194\n",
      "Epoch [15/20], Step [300/313], D Loss: 0.6812, G Loss: 1.0568\n",
      "Epoch [16/20], Step [0/313], D Loss: 0.6757, G Loss: 1.0089\n",
      "Epoch [16/20], Step [100/313], D Loss: 0.6878, G Loss: 0.9614\n",
      "Epoch [16/20], Step [200/313], D Loss: 0.7012, G Loss: 1.0158\n",
      "Epoch [16/20], Step [300/313], D Loss: 0.6798, G Loss: 0.9752\n",
      "Epoch [17/20], Step [0/313], D Loss: 0.6823, G Loss: 1.0145\n",
      "Epoch [17/20], Step [100/313], D Loss: 0.7042, G Loss: 0.9316\n",
      "Epoch [17/20], Step [200/313], D Loss: 0.6768, G Loss: 0.9887\n",
      "Epoch [17/20], Step [300/313], D Loss: 0.6860, G Loss: 0.9680\n",
      "Epoch [18/20], Step [0/313], D Loss: 0.6911, G Loss: 1.0049\n",
      "Epoch [18/20], Step [100/313], D Loss: 0.6906, G Loss: 0.9695\n",
      "Epoch [18/20], Step [200/313], D Loss: 0.7012, G Loss: 0.9098\n",
      "Epoch [18/20], Step [300/313], D Loss: 0.6757, G Loss: 0.9665\n",
      "Epoch [19/20], Step [0/313], D Loss: 0.6834, G Loss: 0.9604\n",
      "Epoch [19/20], Step [100/313], D Loss: 0.6845, G Loss: 0.9520\n",
      "Epoch [19/20], Step [200/313], D Loss: 0.6850, G Loss: 0.9606\n",
      "Epoch [19/20], Step [300/313], D Loss: 0.6715, G Loss: 0.9422\n",
      "Saved sample outputs for epoch 20\n",
      "Saved model weights for epoch 20\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "# Pretrain the generator\n",
    "pretrain_G(net_G, train_dl, pretrain_optimizer, pretrain_criterion, epochs=pretrain_epochs)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lambda_L1 = max(100.0 / (epoch + 1), 1.0)  # Dynamically adjust lambda_L1\n",
    "\n",
    "    for i, data in enumerate(train_dl):\n",
    "        # Load data\n",
    "        real_L = data['L'].to(device)  # Grayscale input\n",
    "        real_ab = data['ab'].to(device)  # Ground truth color channels\n",
    "        \n",
    "        # ==========================================\n",
    "        # Train Discriminator\n",
    "        # ==========================================\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Real images (input + ground truth)\n",
    "        real_input = torch.cat([real_L, real_ab], dim=1)  # Concatenate grayscale and color\n",
    "        real_validity = net_D(real_input)  # Discriminator output for real images\n",
    "        real_loss = adversarial_loss(real_validity, torch.ones_like(real_validity, device=device))  # Target: 1 (real)\n",
    "\n",
    "        # Fake images (input + generated output)\n",
    "        fake_ab = net_G(real_L)  # Generator's output\n",
    "        fake_input = torch.cat([real_L, fake_ab], dim=1)  # Concatenate grayscale and fake color\n",
    "        fake_validity = net_D(fake_input.detach())  # Discriminator output for fake images\n",
    "        fake_loss = adversarial_loss(fake_validity, torch.zeros_like(fake_validity, device=device))  # Target: 0 (fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ==========================================\n",
    "        # Train Generator\n",
    "        # ==========================================\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Adversarial loss for generator\n",
    "        fake_validity = net_D(fake_input)  # Discriminator's response to fake images\n",
    "        g_adv_loss = adversarial_loss(fake_validity, torch.ones_like(fake_validity, device=device))  # Target: 1 (fool D)\n",
    "\n",
    "        # L1 loss for generator\n",
    "        g_l1_loss = lambda_L1 * l1_loss(fake_ab, real_ab)  # Pixel-wise similarity\n",
    "\n",
    "        # Total generator loss\n",
    "        g_loss = g_adv_loss + g_l1_loss\n",
    "        g_loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        nn.utils.clip_grad_norm_(net_G.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ==========================================\n",
    "        # Logging and visualization (optional)\n",
    "        # ==========================================\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{NUM_EPOCHS}], Step [{i}/{len(train_dl)}], \"\n",
    "                  f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # Save sample outputs every 5 epochs\n",
    "    # ==========================================\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            # Take a batch of 8 grayscale images\n",
    "            sample_L = real_L[:8]\n",
    "            sample_fake_ab = net_G(sample_L)  # Generate fake color channels\n",
    "            \n",
    "            # Reverse normalization for saved images\n",
    "            real_L = (sample_L + 1.0) * 50.0  # Reverse normalization for L channel\n",
    "            sample_fake_ab = sample_fake_ab * 128.0  # Reverse normalization for ab channels\n",
    "\n",
    "            # Combine L and ab channels to form the LAB image\n",
    "            sample_fake_lab = torch.cat([real_L, sample_fake_ab], dim=1)  # Concatenate L and ab\n",
    "\n",
    "            # Convert from LAB to RGB\n",
    "            sample_fake_rgb = []\n",
    "            for i in range(len(sample_fake_lab)):\n",
    "                lab_image = sample_fake_lab[i].cpu().numpy().transpose(1, 2, 0)  # Convert to HWC format\n",
    "                rgb_image = lab2rgb(lab_image)  # Convert LAB to RGB\n",
    "                sample_fake_rgb.append(torch.from_numpy(rgb_image).permute(2, 0, 1))  # Convert back to tensor\n",
    "\n",
    "            # Save as grid\n",
    "            save_image(torch.stack(sample_fake_rgb), f\"sample_epoch_{epoch+1}.png\", nrow=4)\n",
    "            print(f\"Saved sample outputs for epoch {epoch+1}\")\n",
    "\n",
    "         # Save model weights\n",
    "        torch.save(net_G.state_dict(), f\"/kaggle/working/net_G_epoch_{epoch+1}.pth\")\n",
    "        torch.save(net_D.state_dict(), f\"/kaggle/working/net_D_epoch_{epoch+1}.pth\")\n",
    "        print(f\"Saved model weights for epoch {epoch+1}\")\n",
    "    \n",
    "    # Step scheduler for both generators and discriminators\n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2699575,
     "sourceId": 4643634,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22039.646131,
   "end_time": "2024-12-11T23:42:22.486696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-11T17:35:02.840565",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
